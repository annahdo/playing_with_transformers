{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8812879",
   "metadata": {},
   "source": [
    "# Activation addition in Llama with custom wrappers\n",
    "\n",
    "This notebook shows how to extract and manipulate internal activations of Llama Transformer model. All you need is access to a trained model (either you have it downloaded locally and update the `model_path` accordingly or you have access to models via Huggingface and get an [authentication token](https://huggingface.co/docs/hub/security-tokens).) You also might wanna make sure you have a gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d78bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1043a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules\n",
    "import sys\n",
    "import importlib\n",
    "# join the path to the modules to the current working directory\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"modules\"))\n",
    "import wrapping\n",
    "import utils\n",
    "\n",
    "importlib.reload(wrapping)\n",
    "importlib.reload(utils)\n",
    "\n",
    "from wrapping import WrappedModel\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3965aad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8380d539f08041578f5526771b810574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "model_name = \"llama-7b\"\n",
    "model_path = f\"huggyllama/{model_name}\"\n",
    "\n",
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left' \n",
    "\n",
    "num_hidden_layers = model.config.num_hidden_layers\n",
    "hidden_size = model.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714816fa",
   "metadata": {},
   "source": [
    "# Activation addition\n",
    "\n",
    "Modify the code as you want. Important parameters are:\n",
    "\n",
    "* `layer_id`: layer at which activation addition is performed\n",
    "* `block_name`: block at which activation addition is performed. Must be one of `[\"decoder_block\", \"self_attn\", \"mlp\", 'input_layernorm\", \"post_attention_layernorm\"]`\n",
    "* `sentences`: list of strings that are modified with internal activations\n",
    "* `prompt1`: first string to encode\n",
    "* `prompt2`: 2nd string to encode\n",
    "* `coeff`: coefficient with which to multiply normalized difference between `prompt1` and `prompt2`\n",
    "* `token_pos`: list of token positions where the difference is applied (if set to None it is applied to every token)\n",
    "* `max_new_tokens`: how many new tokens to generate\n",
    "* `textfile`:       a textfile to save results to (you can generate a timestamped one with `make_new_file()`)\n",
    "\n",
    "The function `apply_activation_difference` does the activation addition by calculating internal representations of `prompt1` and `prompt2` (at the layer and block determined when wrapping the model). The difference is calculated and normalized. This difference is the activation that is added. The function then loops through the given `sentences` and adds the normalized difference multiplied by `coeff` to the internal activations of each sentence at `token_pos`, generating new text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6984095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences:      list of strings that are modified with internal activations\n",
    "# prompt1:        first string to encode\n",
    "# prompt2:        2nd string to encode\n",
    "# coeff:          coefficient with which to multiply normalized difference between prompt1 and prompt2\n",
    "# token_pos:      list of token positions where the difference is applied \n",
    "#                 (if set to None it is applied to every token)\n",
    "# max_new_tokens: how many new tokens to generate\n",
    "# textfile:       a textfile to save results to (you can generate a timestamped one with make_new_file())\n",
    "# layer_ids:      layers at which activation addition is performed\n",
    "# block_names:    blocks at which activation addition is performed. \n",
    "#                 must be in [\"decoder_block\", \"self_attn\", \"mlp\", 'input_layernorm\", \"post_attention_layernorm\"]\n",
    "\n",
    "sentences = [\n",
    "    \"I think dogs are \", \n",
    "    \"I think cats are \", \n",
    "    \"I hate you because\",\n",
    "    \"I love you because\",\n",
    "    \"I think of you as\",    \n",
    "    \"I think you're\",\n",
    "    \"Today I feel\",\n",
    "]\n",
    "\n",
    "prompt1 = \"Love\"\n",
    "prompt2 = \"Hate\"\n",
    "coeff = 10\n",
    "token_pos = None\n",
    "max_new_tokens = 20\n",
    "textfile = None\n",
    "layer_ids = [5]\n",
    "block_names = [\"decoder_block\"]\n",
    "\n",
    "# WRAP MODEL\n",
    "# create wrapped model\n",
    "wrapped_model = WrappedModel(model, tokenizer)\n",
    "# make sure nothing is wrapped from previous runs\n",
    "wrapped_model.unwrap()\n",
    "\n",
    "for block_name in block_names:\n",
    "    for layer_id in layer_ids:\n",
    "        wrapped_model.wrap_block(layer_id, block_name=block_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff190f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_directions(directions):\n",
    "    for block_name in block_names:\n",
    "        for layer_id in layer_ids:\n",
    "            directions[block_name][layer_id] /= directions[block_name][layer_id].norm()\n",
    "        \n",
    "    return directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe5660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0472486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1875,  0.2435, -0.2504,  ...,  0.0443,  0.0717, -0.0887],\n",
      "       device='cuda:0')\n",
      "tensor(16.2701, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(directions[block_names[0]][layer_ids[0]])\n",
    "print(directions[block_names[0]][layer_ids[0]].norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91dd40bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are 100% better than cats.\n",
      "I think dogs are 100% better\n",
      "\n",
      "I think cats are 100% evil.\n",
      "I think cats are 100% evil. I\n",
      "\n",
      "I hate you because you are so beautiful.\n",
      "I hate you because you are so beautiful. I hate you because you\n",
      "\n",
      "I love you because you are my friend.\n",
      "I love you because you are my friend. I love you because you\n",
      "\n",
      "I think of you as a friend, and I hope you will be one of mine.\n",
      "I am a 20\n",
      "\n",
      "I think you're right. I'm not sure what the problem is, but I'm going to try to\n",
      "\n",
      "Today I feel like I’m in a bit of a rut. I’m not sure what to write\n",
      "\n",
      "------------------------------\n",
      "Positive activation addition\n",
      "\n",
      "I think dogs are 100% pure and unconditional love.\n",
      "I think dogs are 100\n",
      "\n",
      "I think cats are 100% pure evil.\n",
      "I think cats are 100% pure evil\n",
      "\n",
      "I hate you because you are my best friend.\n",
      "I love you because you are my best friend.\n",
      "I love\n",
      "\n",
      "I love you because you are my best friend.\n",
      "I love you because you are my best friend. I love you\n",
      "\n",
      "I think of you as a friend, a brother, a son, a father, a husband, a grandfather, a\n",
      "\n",
      "I think you're right. I'm not sure what the point of this thread is.\n",
      "I'm not\n",
      "\n",
      "Today I feel like I’m in a bit of a rut. I’m not sure what to write\n",
      "\n",
      "------------------------------\n",
      "Negative activation addition\n",
      "\n",
      "I think dogs are 100% evil.\n",
      "I think they are the most evil thing on the planet.\n",
      "\n",
      "\n",
      "I think cats are 100% evil.\n",
      "I think cats are 100% evil. I\n",
      "\n",
      "I hate you because you're a Yankee.\n",
      "I hate you because you're a Red Sox fan\n",
      "\n",
      "I love you because you are not like me.\n",
      "I hate you because you do not do what I do.\n",
      "\n",
      "\n",
      "I think of you as a friend.\n",
      "I think of you as a friend.\n",
      "I think of you as a friend\n",
      "\n",
      "I think you're right. I'm not sure what the problem is, but I'm pretty sure it'\n",
      "\n",
      "Today I feel like I'm in a rut. I'm not sure what to do. I'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printout = True\n",
    "calc_neutral = True\n",
    "\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c19188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are 100% better than cats.\n",
      "I think dogs are 100% better\n",
      "\n",
      "I think cats are 100% evil.\n",
      "I think cats are 100% evil. I\n",
      "\n",
      "I hate you because you are so beautiful.\n",
      "I hate you because you are so beautiful. I hate you because you\n",
      "\n",
      "I love you because you are my friend.\n",
      "I love you because you are my friend. I love you because you\n",
      "\n",
      "I think of you as a friend, and I hope you will be one of mine.\n",
      "I am a 20\n",
      "\n",
      "I think you're right. I'm not sure what the problem is, but I'm going to try to\n",
      "\n",
      "Today I feel like I’m in a bit of a rut. I’m not sure what to write\n",
      "\n",
      "------------------------------\n",
      "Positive activation addition\n",
      "\n",
      "I think dogs are 100% purebred.\n",
      "I think dogs are 100% purebre\n",
      "\n",
      "I think cats are 100% right.\n",
      "I think cats are 100% right.\n",
      "\n",
      "\n",
      "I hate you because you are a liar.\n",
      "I hate you because you are a thief.\n",
      "I hate\n",
      "\n",
      "I love you because you are my friend.\n",
      "I love you because you are my friend.\n",
      "I love you because\n",
      "\n",
      "I think of you as a friend, a friend who is always there for me.\n",
      "I think of you as a friend\n",
      "\n",
      "I think you're right. I'm not sure if it's a good thing or a bad thing, but\n",
      "\n",
      "Today I feel like I’m in a bit of a rut. I’m not sure if it’\n",
      "\n",
      "------------------------------\n",
      "Negative activation addition\n",
      "\n",
      "I think dogs are 100% more intelligent than humans.\n",
      "I think I'm going to be a\n",
      "\n",
      "I think cats are 100% evil.\n",
      "I think cats are 100% evil. I\n",
      "\n",
      "I hate you because you are so beautiful.\n",
      "I hate you because you are so beautiful. I hate you because you\n",
      "\n",
      "I love you because you are my friend.\n",
      "I love you because you are my friend. I love you because you\n",
      "\n",
      "I think of you as a friend.\n",
      "I think of you as a friend. I think of you as a friend.\n",
      "\n",
      "I think you're right.\n",
      "I'm not sure what to do.\n",
      "I'm not sure what to\n",
      "\n",
      "Today I feel like I’m in a rut. I’m not sure what to do. I’\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"happy\"\n",
    "prompt2 = \"depressed\"\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cca5ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No activation addition\n",
      "\n",
      "I think dogs are 100% better than cats.\n",
      "I think dogs are 100% better\n",
      "\n",
      "I think cats are 100% evil.\n",
      "I think cats are 100% evil. I\n",
      "\n",
      "I hate you because you are so beautiful.\n",
      "I hate you because you are so beautiful. I hate you because you\n",
      "\n",
      "I love you because you are my friend.\n",
      "I love you because you are my friend. I love you because you\n",
      "\n",
      "I think of you as a friend, and I hope you will be one of mine.\n",
      "I am a 20\n",
      "\n",
      "I think you're right. I'm not sure what the problem is, but I'm going to try to\n",
      "\n",
      "Today I feel like I’m in a bit of a rut. I’m not sure what to write\n",
      "\n",
      "------------------------------\n",
      "Positive activation addition\n",
      "\n",
      "I think dogs are 100% better than cats.\n",
      "I think dogs are 100% better\n",
      "\n",
      "I think cats are 100% better than dogs.\n",
      "I think cats are 100% better\n",
      "\n",
      "I hate you because you are so happy.\n",
      "I love you because you are so happy.\n",
      "I love you because\n",
      "\n",
      "I love you because you are so beautiful.\n",
      "I love you because you are so beautiful.\n",
      "I love you because\n",
      "\n",
      "I think of you as a friend, and I hope you have a great day.\n",
      "I'm a 20\n",
      "\n",
      "I think you're right about the 1000000000000000\n",
      "\n",
      "Today I feel like I’m in a good place. I’m not sure what it is, but I\n",
      "\n",
      "------------------------------\n",
      "Negative activation addition\n",
      "\n",
      "I think dogs are 100% better than cats.\n",
      "I think dogs are 100% better\n",
      "\n",
      "I think cats are 100% evil.\n",
      "I think cats are 100% evil.\n",
      "\n",
      "\n",
      "I hate you because you are not a good God.\n",
      "I hate you because you are not a God.\n",
      "I\n",
      "\n",
      "I love you because you are my brother.\n",
      "I love you because you are my sister.\n",
      "I love you because\n",
      "\n",
      "I think of you as a friend, a brother, a father, a son, a lover, a husband, a\n",
      "\n",
      "I think you're right. I'm not sure what to do. I'm not going to a world.\n",
      "\n",
      "Today I feel like I’m in a dream. I’m not sure if I’m awake or\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"I am happy\"\n",
    "prompt2 = \"I am angry\"\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada78c95",
   "metadata": {},
   "source": [
    "# Quantitative evaluation with sentiment analysis\n",
    "\n",
    "Idea: get the model to write some sentences and then do a sentiment analysis on the generated sentences using the model itself. The results with this approach seem a bit more promising , but still far from obviously working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60532013",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = [\n",
    "    \"dogs\", \"cats\", \"my neighbour\", \"my wife\", \"my kids\", \"my teacher\",\n",
    "    \"myself\", \"my childhood\", \"my friends\", \"my colleagues\", \n",
    "    \"my parents\", \"my cousin\", \"my pet\", \"my school\", \"my job\",\n",
    "    \"my car\", \"my house\", \"my city\", \"my country\", \"my hobbies\", \n",
    "    \"my garden\", \"my vacation\", \"my past\", \"my future\", \"my dreams\",\n",
    "    \"my boss\", \"my room\", \"my computer\", \"my phone\", \"my kitchen\",\n",
    "    \"my books\", \"my music\", \"my films\", \"my clothes\", \"my photographs\",\n",
    "    \"my ideas\", \"my projects\", \"my goals\", \"my achievements\", \"my failures\",\n",
    "    \"my holidays\", \"my adventures\", \"my experiences\", \"my challenges\", \"my victories\",\n",
    "    \"my secrets\", \"my fears\", \"my hopes\", \"my regrets\", \"my sorrows\",\n",
    "    \"my joys\", \"my food\", \"my studies\", \"my sport\", \"my team\",\n",
    "    \"my morning routine\", \"my evening routine\", \"my workout\", \"my diet\", \"my coach\",\n",
    "    \"my first love\", \"my ex\", \"my current partner\", \"my childhood friend\", \"my classmate\",\n",
    "    \"my professor\", \"a popular author\", \"a famous actor\", \"a renowned artist\", \"my role model\",\n",
    "    \"a catchy song\", \"a blockbuster movie\", \"a popular TV show\", \"a best-selling book\", \"a trending game\",\n",
    "    \"an interesting place\", \"my hometown\", \"a local restaurant\", \"a common dish\", \"a refreshing drink\",\n",
    "    \"a tasty dessert\", \"a beautiful season\", \"a vivid memory\", \"a famous quote\", \"a national holiday\",\n",
    "    \"my weekend\", \"my daily routine\", \"my free time\", \"my lifestyle\", \"my decision\",\n",
    "    \"my journey\", \"my path\", \"my destination\", \"a common animal\", \"my childhood home\",\n",
    "    \"a vibrant color\", \"a casual outfit\", \"my collection\", \"a classic toy\", \"a funny joke\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51686530",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [f\"When thinking about {s} I feel\" for s in stuff]\n",
    "max_new_tokens = 20\n",
    "instruction = \" On a scale of 1 to 5, where 1 is very negative and 5 is very positive, the previous text would get this amount of points: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd9909c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b957c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 10\n",
    "file_path = \"results/activation_addition/naive\"\n",
    "id_str = f\"{layer_ids[0]}-{layer_ids[-1]}\"\n",
    "textfile = make_new_file(path=file_path, filename=f\"naive_aa_{model_name}_{id_str}_{block_name}\")\n",
    "\n",
    "with open(textfile, \"w\") as f:\n",
    "    f.write(f\"Quantitative evaluation on {len(sentences)} sentences\\n\\n\")\n",
    "    f.write(f\"sample sentence: {sentences[0]}\\n\")\n",
    "    f.write(f\"Continuing the sentence, then doing sentiment analysis on the results.\\n\")\n",
    "    f.write(f\"Instruction for judgement: {instruction}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f935851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.69s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Positive activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.42s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Negative activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.42s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Making judgements\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Turning judgements into numbers\n",
      "\n",
      "neutral:  3.85\n",
      "positive: 4.58\n",
      "negative: 3.56\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"I feel happy\"\n",
    "prompt2 = \"I feel angry\"\n",
    "printout = False\n",
    "calc_neutral = True\n",
    "\n",
    "config_to_textfile(textfile, prompt1, prompt2, coeff, layer_ids[0], block_names[0], token_pos, max_new_tokens)\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)\n",
    "judgements = judge_generations(wrapped_model, generations, instruction)\n",
    "judgements = save_judgements(judgements, textfile=textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b8798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Positive activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.42s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Negative activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.42s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Making judgements\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Turning judgements into numbers\n",
      "\n",
      "neutral:  nan\n",
      "positive: 4.19\n",
      "negative: 3.24\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"Love\"\n",
    "prompt2 = \"Hate\"\n",
    "calc_neutral = False\n",
    "\n",
    "config_to_textfile(textfile, prompt1, prompt2, coeff, layer_ids[0], block_names[0], token_pos, max_new_tokens)\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)\n",
    "judgements = judge_generations(wrapped_model, generations, instruction)\n",
    "judgements = save_judgements(judgements, textfile=textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34da1533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Positive activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.43s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Negative activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.43s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Making judgements\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Turning judgements into numbers\n",
      "\n",
      "neutral:  nan\n",
      "positive: 4.25\n",
      "negative: 2.79\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"My life is awesome\"\n",
    "prompt2 = \"My  life is awful\"\n",
    "calc_neutral = False\n",
    "\n",
    "config_to_textfile(textfile, prompt1, prompt2, coeff, layer_ids[0], block_names[0], token_pos, max_new_tokens)\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)\n",
    "judgements = judge_generations(wrapped_model, generations, instruction)\n",
    "judgements = save_judgements(judgements, textfile=textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e128d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Positive activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.42s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Negative activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.41s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Making judgements\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Turning judgements into numbers\n",
      "\n",
      "neutral:  nan\n",
      "positive: 4.39\n",
      "negative: 2.73\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"happy\"\n",
    "prompt2 = \"depressed\"\n",
    "calc_neutral = False\n",
    "\n",
    "config_to_textfile(textfile, prompt1, prompt2, coeff, layer_ids[0], block_names[0], token_pos, max_new_tokens)\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)\n",
    "judgements = judge_generations(wrapped_model, generations, instruction)\n",
    "judgements = save_judgements(judgements, textfile=textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa019d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Positive activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.43s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Negative activation addition\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.41s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Making judgements\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Turning judgements into numbers\n",
      "\n",
      "neutral:  nan\n",
      "positive: 4.42\n",
      "negative: 3.18\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"I am happy\"\n",
    "prompt2 = \"I am depressed\"\n",
    "calc_neutral = False\n",
    "\n",
    "config_to_textfile(textfile, prompt1, prompt2, coeff, layer_ids[0], block_names[0], token_pos, max_new_tokens)\n",
    "directions = get_difference(wrapped_model, prompt1, prompt2, layer_ids, block_names)\n",
    "directions = normalize_directions(directions)\n",
    "generations = activation_editing(wrapped_model, sentences, directions, \n",
    "                                   coeff=coeff, token_pos=token_pos, max_new_tokens=max_new_tokens,\n",
    "                                   textfile=textfile, printout=printout, calc_neutral=calc_neutral)\n",
    "judgements = judge_generations(wrapped_model, generations, instruction)\n",
    "judgements = save_judgements(judgements, textfile=textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492dd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
