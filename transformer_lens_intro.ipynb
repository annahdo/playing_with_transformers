{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to how transformer lens works\n",
    "\n",
    "This notebook shows how to access and modify internal model activations using the transformer lens library (version transformer_lens-1.8.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "dtype = torch.bfloat16\n",
    "# we want the padding side to be left as we want an easy way to access the last token\n",
    "padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3ad529bc8a443f81d063b64ded422f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model'meta-llama/Llama-2-7b-hf'meta-llama/Llama-2-7b-chat-hf\n",
    "model_name = \"llama-7b\"\n",
    "model_path = f\"huggyllama/{model_name}\"\n",
    "org_model = AutoModelForCausalLM.from_pretrained(model_path).to(device, dtype=dtype)\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.padding_side = padding_side\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model llama-7b-hf into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# create a hooked transformer\n",
    "model = HookedTransformer.from_pretrained(\"llama-7b-hf\", \n",
    "                                          hf_model=org_model.to(\"cpu\"),\n",
    "                                          fold_ln=False, \n",
    "                                          center_writing_weights=False, \n",
    "                                          center_unembed=False, \n",
    "                                          tokenizer=tokenizer,\n",
    "                                          default_padding_side=padding_side,\n",
    "                                          dtype=dtype)\n",
    "\n",
    "model.tokenizer.padding_side = padding_side\n",
    "model.tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_model = org_model.to(device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks\n",
    "\n",
    "I ran into some issues while trying to figure out activation addition as the results did not match the results I had gotten with other approaches (custom wrapping module and pytorch hooks), so I decided to run some sanity checks on the HookedTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff in ids: tensor(0., device='cuda:0')\n",
      "diff in attention mask: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# compare tokenizers\n",
    "test_sentences = [\"The quick brown fox jumps over the lazy dog\",\n",
    "                  \"this is another sentence\",\n",
    "                  \"and a third one\",\n",
    "                  \" some nonsense: sFglk 1   ,.<<< 2lkaAASX#sdfk %js 23 kasdg \"]\n",
    "                \n",
    "                \n",
    "org_ids = tokenizer(test_sentences, return_tensors=\"pt\", padding=True).to(device)\n",
    "ids = model.tokenizer(test_sentences, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "print(\"diff in ids:\", (org_ids.input_ids - ids.input_ids).float().pow(2).mean())\n",
    "print(\"diff in attention mask:\", (org_ids.attention_mask - ids.attention_mask).float().pow(2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in model output with and without padding being relevant\n",
    "\n",
    "I get large differences between original and hooked model when using padding.\n",
    "\n",
    "If I iterate through sentences the difference in logits is smaller but still significant.\n",
    "When I switch to `dtype=float32` the second issue disappears but differences when using padding is still high.\n",
    "\n",
    "So there is definitely sth wrong with the padding and probably sth wrong with the precision? I get similar results, for left and right padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff in logits when padding: 0.05034\n",
      "diff in logits no padding: 0.001097\n"
     ]
    }
   ],
   "source": [
    "# compare tokenizers\n",
    "test_sentences = [\"The quick brown fox jumps over the lazy dog\",\n",
    "                  \"this is another sentence\",\n",
    "                  \"and a third one\",\n",
    "                  \" some nonsense: sFglk 1   ,.<<< 2lkaAASX#sdfk %js 23 kasdg \"]\n",
    "\n",
    "\n",
    "# compare model outputs\n",
    "org_model.eval()\n",
    "model.eval()\n",
    "ids = tokenizer(test_sentences, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    org_output = org_model(ids[\"input_ids\"], attention_mask=ids[\"attention_mask\"])\n",
    "    output = model(ids[\"input_ids\"], attention_mask=ids[\"attention_mask\"], return_type=\"logits\")\n",
    "\n",
    "print(\"diff in logits when padding: {:.4g}\".format((org_output.logits - output).pow(2).mean()))\n",
    "\n",
    "# is this difference due to the padding?\n",
    "diff = 0\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "\n",
    "    single_id = tokenizer(test_sentences[i], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        org_output = org_model(single_id[\"input_ids\"])\n",
    "        output = model(single_id[\"input_ids\"], return_type=\"logits\")\n",
    "\n",
    "    diff += (org_output.logits - output).pow(2).mean()\n",
    "\n",
    "print(\"diff in logits no padding: {:.4g}\".format(diff.item() / len(test_sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare hidden states layerwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "org_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(test_sentence, return_tensors=\"pt\").to(device)\n",
    "    org_hidden_states = org_model(inputs[\"input_ids\"], output_hidden_states=True)[\"hidden_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(test_sentence, return_tensors=\"pt\").to(device)\n",
    "    _, cache_tl = model.run_with_cache(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 5.635e-08, 1: 2.794e-07, 2: 7.525e-07, 3: 1.565e-06, 4: 3.546e-06, 5: 5.245e-06, 6: 7.629e-06, 7: 1.276e-05, 8: 1.729e-05, 9: 2.205e-05, 10: 2.742e-05, 11: 3.481e-05, 12: 4.053e-05, 13: 4.673e-05, 14: 5.317e-05, 15: 6.437e-05, 16: 8.392e-05, 17: 0.0001078, 18: 0.0001392, 19: 0.0001783, 20: 0.0002384, 21: 0.0002956, 22: 0.0003586, 23: 0.0004368, 24: 0.0005264, 25: 0.0006409, 26: 0.0007782, 27: 0.0009232, 28: 0.001137, 29: 0.001404, 30: 0.001793, 31: 9.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diffs = torch.zeros(len(org_hidden_states)-1)\n",
    "\n",
    "for layer_id in range(len(org_hidden_states)-1):\n",
    "    cache_name = f\"blocks.{layer_id}.hook_resid_post\"\n",
    "    diffs[layer_id] = (org_hidden_states[layer_id+1] - cache_tl[cache_name]).pow(2).mean().item()\n",
    "\n",
    "# print diffs with 4 significant digits\n",
    "print(', '.join(\"{}: {:.4g}\".format(i,value) for i, value in enumerate(diffs)))\n",
    "\n",
    "# plot the differences in log scale\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(diffs)\n",
    "plt.yscale(\"log\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and modifying internal model activations\n",
    "\n",
    "### Access hidden activations\n",
    "\n",
    "We can access hidden activations of the residual streem by passing the `output_hidden_states` keyword. But if we want other hidden states we need some way to hook into the other transformer layers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['logits', 'past_key_values', 'hidden_states'])\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "org_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(test_sentence, return_tensors=\"pt\").to(device)\n",
    "    output = org_model(**inputs, output_hidden_states=True)\n",
    "    print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len hidden states: 33\n",
      "shape of hidden states: torch.Size([1, 12, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(f\"len hidden states: {len(output.hidden_states)}\")\n",
    "print(f\"shape of hidden states: {output.hidden_states[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the residual layer output of layer layer_id is\n",
    "# output.hidden_states[layer_id + 1] as the first hidden state is the input embedding\n",
    "layer_id = 5\n",
    "hidden_states = output.hidden_states[layer_id + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(test_sentence, return_tensors=\"pt\").to(device)\n",
    "    _, cache = model.run_with_cache(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE hidden states: 5.245e-06\n"
     ]
    }
   ],
   "source": [
    "# define what layer/module you want information from\n",
    "cache_name = f\"blocks.{layer_id}.hook_resid_post\"\n",
    "hidden_states_tl = cache[cache_name]\n",
    "\n",
    "# mse between the two hidden states\n",
    "print(f\"MSE hidden states: {(hidden_states - hidden_states_tl).pow(2).mean():.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available blocks: dict_keys(['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_pre_linear', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_pre_linear', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_pre_linear', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_pre_linear', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_pre_linear', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_pre_linear', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_rot_q', 'blocks.6.attn.hook_rot_k', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_pre_linear', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_rot_q', 'blocks.7.attn.hook_rot_k', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_pre_linear', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_rot_q', 'blocks.8.attn.hook_rot_k', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_pre_linear', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_rot_q', 'blocks.9.attn.hook_rot_k', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_pre_linear', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_rot_q', 'blocks.10.attn.hook_rot_k', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_pre_linear', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_rot_q', 'blocks.11.attn.hook_rot_k', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_pre_linear', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', 'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', 'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', 'blocks.12.attn.hook_rot_q', 'blocks.12.attn.hook_rot_k', 'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', 'blocks.12.attn.hook_z', 'blocks.12.hook_attn_out', 'blocks.12.hook_resid_mid', 'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_pre_linear', 'blocks.12.mlp.hook_post', 'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', 'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', 'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', 'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', 'blocks.13.attn.hook_rot_q', 'blocks.13.attn.hook_rot_k', 'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', 'blocks.13.attn.hook_z', 'blocks.13.hook_attn_out', 'blocks.13.hook_resid_mid', 'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_pre_linear', 'blocks.13.mlp.hook_post', 'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', 'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', 'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', 'blocks.14.attn.hook_rot_q', 'blocks.14.attn.hook_rot_k', 'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', 'blocks.14.attn.hook_z', 'blocks.14.hook_attn_out', 'blocks.14.hook_resid_mid', 'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_pre_linear', 'blocks.14.mlp.hook_post', 'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', 'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', 'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', 'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_rot_q', 'blocks.15.attn.hook_rot_k', 'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', 'blocks.15.attn.hook_z', 'blocks.15.hook_attn_out', 'blocks.15.hook_resid_mid', 'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_pre_linear', 'blocks.15.mlp.hook_post', 'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', 'blocks.16.hook_resid_pre', 'blocks.16.ln1.hook_scale', 'blocks.16.ln1.hook_normalized', 'blocks.16.attn.hook_q', 'blocks.16.attn.hook_k', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_rot_q', 'blocks.16.attn.hook_rot_k', 'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', 'blocks.16.attn.hook_z', 'blocks.16.hook_attn_out', 'blocks.16.hook_resid_mid', 'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', 'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_pre_linear', 'blocks.16.mlp.hook_post', 'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_post', 'blocks.17.hook_resid_pre', 'blocks.17.ln1.hook_scale', 'blocks.17.ln1.hook_normalized', 'blocks.17.attn.hook_q', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_rot_q', 'blocks.17.attn.hook_rot_k', 'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', 'blocks.17.attn.hook_z', 'blocks.17.hook_attn_out', 'blocks.17.hook_resid_mid', 'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', 'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_pre_linear', 'blocks.17.mlp.hook_post', 'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_post', 'blocks.18.hook_resid_pre', 'blocks.18.ln1.hook_scale', 'blocks.18.ln1.hook_normalized', 'blocks.18.attn.hook_q', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_rot_q', 'blocks.18.attn.hook_rot_k', 'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', 'blocks.18.attn.hook_z', 'blocks.18.hook_attn_out', 'blocks.18.hook_resid_mid', 'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_pre_linear', 'blocks.18.mlp.hook_post', 'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_post', 'blocks.19.hook_resid_pre', 'blocks.19.ln1.hook_scale', 'blocks.19.ln1.hook_normalized', 'blocks.19.attn.hook_q', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_rot_q', 'blocks.19.attn.hook_rot_k', 'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', 'blocks.19.attn.hook_z', 'blocks.19.hook_attn_out', 'blocks.19.hook_resid_mid', 'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', 'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_pre_linear', 'blocks.19.mlp.hook_post', 'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_post', 'blocks.20.hook_resid_pre', 'blocks.20.ln1.hook_scale', 'blocks.20.ln1.hook_normalized', 'blocks.20.attn.hook_q', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_rot_q', 'blocks.20.attn.hook_rot_k', 'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', 'blocks.20.attn.hook_z', 'blocks.20.hook_attn_out', 'blocks.20.hook_resid_mid', 'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_pre_linear', 'blocks.20.mlp.hook_post', 'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_post', 'blocks.21.hook_resid_pre', 'blocks.21.ln1.hook_scale', 'blocks.21.ln1.hook_normalized', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_k', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_rot_q', 'blocks.21.attn.hook_rot_k', 'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', 'blocks.21.attn.hook_z', 'blocks.21.hook_attn_out', 'blocks.21.hook_resid_mid', 'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_pre_linear', 'blocks.21.mlp.hook_post', 'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_post', 'blocks.22.hook_resid_pre', 'blocks.22.ln1.hook_scale', 'blocks.22.ln1.hook_normalized', 'blocks.22.attn.hook_q', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_rot_q', 'blocks.22.attn.hook_rot_k', 'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', 'blocks.22.attn.hook_z', 'blocks.22.hook_attn_out', 'blocks.22.hook_resid_mid', 'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_pre_linear', 'blocks.22.mlp.hook_post', 'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_post', 'blocks.23.hook_resid_pre', 'blocks.23.ln1.hook_scale', 'blocks.23.ln1.hook_normalized', 'blocks.23.attn.hook_q', 'blocks.23.attn.hook_k', 'blocks.23.attn.hook_v', 'blocks.23.attn.hook_rot_q', 'blocks.23.attn.hook_rot_k', 'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', 'blocks.23.attn.hook_z', 'blocks.23.hook_attn_out', 'blocks.23.hook_resid_mid', 'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_pre_linear', 'blocks.23.mlp.hook_post', 'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_post', 'blocks.24.hook_resid_pre', 'blocks.24.ln1.hook_scale', 'blocks.24.ln1.hook_normalized', 'blocks.24.attn.hook_q', 'blocks.24.attn.hook_k', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_rot_q', 'blocks.24.attn.hook_rot_k', 'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', 'blocks.24.attn.hook_z', 'blocks.24.hook_attn_out', 'blocks.24.hook_resid_mid', 'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_pre_linear', 'blocks.24.mlp.hook_post', 'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_post', 'blocks.25.hook_resid_pre', 'blocks.25.ln1.hook_scale', 'blocks.25.ln1.hook_normalized', 'blocks.25.attn.hook_q', 'blocks.25.attn.hook_k', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_rot_q', 'blocks.25.attn.hook_rot_k', 'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', 'blocks.25.attn.hook_z', 'blocks.25.hook_attn_out', 'blocks.25.hook_resid_mid', 'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_pre_linear', 'blocks.25.mlp.hook_post', 'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_post', 'blocks.26.hook_resid_pre', 'blocks.26.ln1.hook_scale', 'blocks.26.ln1.hook_normalized', 'blocks.26.attn.hook_q', 'blocks.26.attn.hook_k', 'blocks.26.attn.hook_v', 'blocks.26.attn.hook_rot_q', 'blocks.26.attn.hook_rot_k', 'blocks.26.attn.hook_attn_scores', 'blocks.26.attn.hook_pattern', 'blocks.26.attn.hook_z', 'blocks.26.hook_attn_out', 'blocks.26.hook_resid_mid', 'blocks.26.ln2.hook_scale', 'blocks.26.ln2.hook_normalized', 'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_pre_linear', 'blocks.26.mlp.hook_post', 'blocks.26.hook_mlp_out', 'blocks.26.hook_resid_post', 'blocks.27.hook_resid_pre', 'blocks.27.ln1.hook_scale', 'blocks.27.ln1.hook_normalized', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k', 'blocks.27.attn.hook_v', 'blocks.27.attn.hook_rot_q', 'blocks.27.attn.hook_rot_k', 'blocks.27.attn.hook_attn_scores', 'blocks.27.attn.hook_pattern', 'blocks.27.attn.hook_z', 'blocks.27.hook_attn_out', 'blocks.27.hook_resid_mid', 'blocks.27.ln2.hook_scale', 'blocks.27.ln2.hook_normalized', 'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_pre_linear', 'blocks.27.mlp.hook_post', 'blocks.27.hook_mlp_out', 'blocks.27.hook_resid_post', 'blocks.28.hook_resid_pre', 'blocks.28.ln1.hook_scale', 'blocks.28.ln1.hook_normalized', 'blocks.28.attn.hook_q', 'blocks.28.attn.hook_k', 'blocks.28.attn.hook_v', 'blocks.28.attn.hook_rot_q', 'blocks.28.attn.hook_rot_k', 'blocks.28.attn.hook_attn_scores', 'blocks.28.attn.hook_pattern', 'blocks.28.attn.hook_z', 'blocks.28.hook_attn_out', 'blocks.28.hook_resid_mid', 'blocks.28.ln2.hook_scale', 'blocks.28.ln2.hook_normalized', 'blocks.28.mlp.hook_pre', 'blocks.28.mlp.hook_pre_linear', 'blocks.28.mlp.hook_post', 'blocks.28.hook_mlp_out', 'blocks.28.hook_resid_post', 'blocks.29.hook_resid_pre', 'blocks.29.ln1.hook_scale', 'blocks.29.ln1.hook_normalized', 'blocks.29.attn.hook_q', 'blocks.29.attn.hook_k', 'blocks.29.attn.hook_v', 'blocks.29.attn.hook_rot_q', 'blocks.29.attn.hook_rot_k', 'blocks.29.attn.hook_attn_scores', 'blocks.29.attn.hook_pattern', 'blocks.29.attn.hook_z', 'blocks.29.hook_attn_out', 'blocks.29.hook_resid_mid', 'blocks.29.ln2.hook_scale', 'blocks.29.ln2.hook_normalized', 'blocks.29.mlp.hook_pre', 'blocks.29.mlp.hook_pre_linear', 'blocks.29.mlp.hook_post', 'blocks.29.hook_mlp_out', 'blocks.29.hook_resid_post', 'blocks.30.hook_resid_pre', 'blocks.30.ln1.hook_scale', 'blocks.30.ln1.hook_normalized', 'blocks.30.attn.hook_q', 'blocks.30.attn.hook_k', 'blocks.30.attn.hook_v', 'blocks.30.attn.hook_rot_q', 'blocks.30.attn.hook_rot_k', 'blocks.30.attn.hook_attn_scores', 'blocks.30.attn.hook_pattern', 'blocks.30.attn.hook_z', 'blocks.30.hook_attn_out', 'blocks.30.hook_resid_mid', 'blocks.30.ln2.hook_scale', 'blocks.30.ln2.hook_normalized', 'blocks.30.mlp.hook_pre', 'blocks.30.mlp.hook_pre_linear', 'blocks.30.mlp.hook_post', 'blocks.30.hook_mlp_out', 'blocks.30.hook_resid_post', 'blocks.31.hook_resid_pre', 'blocks.31.ln1.hook_scale', 'blocks.31.ln1.hook_normalized', 'blocks.31.attn.hook_q', 'blocks.31.attn.hook_k', 'blocks.31.attn.hook_v', 'blocks.31.attn.hook_rot_q', 'blocks.31.attn.hook_rot_k', 'blocks.31.attn.hook_attn_scores', 'blocks.31.attn.hook_pattern', 'blocks.31.attn.hook_z', 'blocks.31.hook_attn_out', 'blocks.31.hook_resid_mid', 'blocks.31.ln2.hook_scale', 'blocks.31.ln2.hook_normalized', 'blocks.31.mlp.hook_pre', 'blocks.31.mlp.hook_pre_linear', 'blocks.31.mlp.hook_post', 'blocks.31.hook_mlp_out', 'blocks.31.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])\n"
     ]
    }
   ],
   "source": [
    "# now we can get hidden representations from any block in the transformer\n",
    "print(f\"Available blocks: {cache.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation addition\n",
    "\n",
    "Define a direction vector and add it to the internal model activations while generating new model output.\n",
    "\n",
    "From the transformer lense documentation:\n",
    "\n",
    "We do this by adding a hook function to that activation. The hook function maps current_activation_value, hook_point to new_activation_value. As the model is run, it computes that activation as normal, and then the hook function is applied to compute a replacement, and that is substituted in for the activation. The hook function can be an arbitrary Python function, so long as it returns a tensor of the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 30\n",
    "random_seed = 0\n",
    "layer_id = 5\n",
    "cache_name = f\"blocks.{layer_id}.hook_resid_post\"\n",
    "token_pos = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape vec1: torch.Size([1, 2, 4096])\n",
      "shape vec2: torch.Size([1, 3, 4096])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    vec1 = model.run_with_cache(\"Love\")[1][cache_name] \n",
    "    vec2 = model.run_with_cache(\"Hate\")[1][cache_name] \n",
    "\n",
    "print(f\"shape vec1: {vec1.shape}\")\n",
    "print(f\"shape vec2: {vec2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE activations 'Love': 0\n",
      "MSE activations 'Hate': 0\n"
     ]
    }
   ],
   "source": [
    "# to not use have to store all activations in the cache we can also use hooks to access internal model activations\n",
    "def get_internal_activations(model, inputs, cache_name, token_pos=-1):\n",
    "\n",
    "    activations = torch.zeros((len(inputs), 1, model.cfg.d_model), dtype=model.cfg.dtype, device=model.cfg.device)\n",
    "    def hook_fn(activation, hook):\n",
    "        activations[:,:,:] = activation[:,token_pos,:].unsqueeze(1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model.run_with_hooks(inputs,\n",
    "                                 fwd_hooks=[(\n",
    "                                     cache_name, \n",
    "                                     hook_fn)])\n",
    "    \n",
    "    return activations\n",
    "\n",
    "sentences = [\"Love\", \"Hate\"]\n",
    "activations = get_internal_activations(model, sentences, cache_name, token_pos=token_pos)\n",
    "\n",
    "print(f\"MSE activations '{sentences[0]}': {(activations[0, 0] - vec1[0, token_pos]).pow(2).mean():.4g}\")\n",
    "print(f\"MSE activations '{sentences[1]}': {(activations[1, 0] - vec2[0, token_pos]).pow(2).mean():.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape direction: torch.Size([1, 1, 4096])\n",
      "norm of direction: 16.25\n"
     ]
    }
   ],
   "source": [
    "direction = vec1[:, token_pos] - vec2[:, token_pos]\n",
    "# reshape to (batch_size, 1, hidden_size)\n",
    "direction = direction.unsqueeze(1)\n",
    "print(f\"shape direction: {direction.shape}\")\n",
    "print(f\"norm of direction: {direction.norm(dim=-1).item():.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hook function\n",
    "def act_add_hook(direction):\n",
    "    \n",
    "    def hook_fn(activation, hook):\n",
    "        output = activation + direction\n",
    "        return output\n",
    "\n",
    "    return hook_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference in logits: 0.3301\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"I think dogs are\",\n",
    "                  \"I think cats are\",\n",
    "                  \"When I wake up, I\",\n",
    "                  \"When I go to work, I\",\n",
    "                  \"Today I feel\",\n",
    "                  \"I am\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # this only sets the hook temporarily\n",
    "    hooked_output = model.run_with_hooks(\n",
    "        test_sentences,\n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=[(\n",
    "            cache_name, \n",
    "            act_add_hook(direction)\n",
    "            )]\n",
    "    )\n",
    "\n",
    "    normal_output = model(test_sentences)\n",
    "    print(f\"difference in logits: {((hooked_output - normal_output)**2).mean():.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, test_sentences, max_new_tokens=20, random_seed=0):\n",
    "    torch.random.manual_seed(random_seed)\n",
    "    with torch.no_grad():\n",
    "        torch.random.manual_seed(random_seed)\n",
    "        inputs = model.tokenizer(test_sentences, return_tensors=\"pt\", padding=True).to(model.cfg.device)\n",
    "        # weirdly enough the generate function does not except list of strings...\n",
    "        # so it's either single string or tensor of tokens (batch_size, seq_len)\n",
    "        output_tokens = model.generate(inputs[\"input_ids\"], max_new_tokens=max_new_tokens, verbose=False)\n",
    "        output_sentences = model.tokenizer.batch_decode(output_tokens, skip_special_tokens=True)\n",
    "\n",
    "        return output_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering in positive direction:\n",
      "\n",
      "\n",
      "I think dogs are man’s best friends until the actual scent began posting him and my family.\n",
      "------------------------------\n",
      "I think cats are bonded by an einot symmetry\n",
      "The symbolic language of You Should Cat presented me with a special reinforced censorship, Rossi\n",
      "------------------------------\n",
      "When I wake up, I fight back to sleep as I travel back to sleep. Using a travel ad, parents celebrate each other cheating alfas wedded wests marriage\n",
      "------------------------------\n",
      "When I go to work, I always see to Helen,\n",
      "My favourite toys!\n",
      "------------------------------\n",
      "Today I feel excited.\n",
      "Why do I love them so much?\n",
      "Dance lovers as ARADs\n",
      "applicant First Interstate Financial\n",
      "------------------------------\n",
      "I am so so so happy about the posting. I’ve to say to an old comparable to a young lady aged.\n",
      "In 199\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks()\n",
    "model.add_hook(name=cache_name, hook=act_add_hook(direction))\n",
    "\n",
    "output_sentences = generate(model, test_sentences, max_new_tokens=max_new_tokens, random_seed=random_seed)\n",
    "print(f\"steering in positive direction:\\n\\n\")\n",
    "for i in range(len(output_sentences)):\n",
    "    print(f\"{output_sentences[i]}\")\n",
    "    print(\"-\"*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering in negative direction:\n",
      "\n",
      "\n",
      "I think dogs are pretty stupid. And I’m a scaredy cow. As my cohortor be auorum moves behind me and I try to finish for\n",
      "------------------------------\n",
      "I think cats are evil, but I know I can’ them some Internet.\n",
      "My candidate for hate crime & speakspeeispeispee…te\n",
      "------------------------------\n",
      "When I wake up, I fight back at the morn, I’m brutal, hate every man. Like I know the cheater Crime, yeah like him,\n",
      "------------------------------\n",
      "When I go to work, I always see to it that I avoid riding to work exacerbating tail winds. And honestly, I always lie upon each half.\n",
      "------------------------------\n",
      "Today I feel like going out shopping and find them.\n",
      "Yeah, the new as ARP right now because I, can't find the word\n",
      "------------------------------\n",
      "I am so so so sorry about last night. I’ve been sick to an extreme comparable to the past day. I know other guy without my\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks()\n",
    "model.add_hook(name=cache_name, hook=act_add_hook(-direction))\n",
    "\n",
    "output_sentences = generate(model, test_sentences, max_new_tokens=max_new_tokens, random_seed=random_seed)\n",
    "print(f\"steering in negative direction:\\n\\n\")\n",
    "for i in range(len(output_sentences)):\n",
    "    print(f\"{output_sentences[i]}\")\n",
    "    print(\"-\"*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no steering:\n",
      "\n",
      "\n",
      "I think dogs are man’s best friends until you take one in a coworking space (when they actually become the bane of my office existence after one slightly\n",
      "------------------------------\n",
      "I think cats are bonded by an einheitscat fysik secret language base. Should we be happy we dont speak that language and dont hold it? Cats\n",
      "------------------------------\n",
      "When I wake up, I fight back to sleep again. When I’m brutally awake, my parents wake me up with music. For some reason, that time\n",
      "------------------------------\n",
      "When I go to work, I always see this thing glowing in the sky early in the morning and later in the day it's really a pretty site to see.\n",
      "\n",
      "------------------------------\n",
      "Today I feel like going out shopping and doing them.\n",
      "Yeah, the new rose gold colour for iPhone 6, 6s and iPhone \n",
      "------------------------------\n",
      "I am so so so sorry about last night. I’ve been sick to my stomach and feel even worse than I did last night. I’\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks()\n",
    "\n",
    "output_sentences = generate(model, test_sentences, max_new_tokens=max_new_tokens, random_seed=random_seed)\n",
    "print(f\"no steering:\\n\\n\")\n",
    "for i in range(len(output_sentences)):\n",
    "    print(f\"{output_sentences[i]}\")\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
